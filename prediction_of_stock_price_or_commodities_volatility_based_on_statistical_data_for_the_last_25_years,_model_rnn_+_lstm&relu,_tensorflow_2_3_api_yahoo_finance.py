# -*- coding: utf-8 -*-
"""Prediction of stock price or commodities volatility based on statistical data for the last 25 years, Model: RNN + LSTM&ReLU, TensorFlow 2.3_API: YAHOO Finance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fX2IZ1PVrpkqncM7XWS_Zf6J17OD_PP9
"""

!pip install tensorflow
#import tensorflow as tf
from tensorflow import keras
#yahoo finance as data source
!pip install yfinance
import yfinance as yf
import flask
from flask import Flask

"""**Prediction of stock price or commodities volatility (NEXT DAY or up to 3 days) based on statistical data for the last 25 years, Model: RNN + LSTM&ReLU, TensorFlow 2.3, API: YAHOO Finance**"""

#See the yahoo finance ticker for your stock symbol
#stock_symbol = 'GAIL.NS'
#stock_symbol = '^GSPC' 
#stock_symbol = 'IBM'
#stock_symbol = 'NG=F'
stock_symbol = 'GC=F' # Gold

#last 5 year#s data with interval of 1 day
data = yf.download(tickers=stock_symbol,period='20y',interval='1d')

type(data)

data.head()

len(data)

data.tail()

import matplotlib.pyplot as plt

opn = data[['Open']]

cln = data[['Close']]

#plt.plot(opn)
plt.plot(cln)

opn.plot()



#import matplotlib.pyplot as plt

#ds = opn.values
ds = cln.values

ds

plt.plot(ds)

import numpy as np

from sklearn.preprocessing import MinMaxScaler

#Using MinMaxScaler for normalizing data between 0 & 1
normalizer = MinMaxScaler(feature_range=(0,1))
ds_scaled = normalizer.fit_transform(np.array(ds).reshape(-1,1))

len(ds_scaled), len(ds)

#Defining test and train data sizes
train_size = int(len(ds_scaled)*0.70)
test_size = len(ds_scaled) - train_size

train_size,test_size

#Splitting data between train and test
ds_train, ds_test = ds_scaled[0:train_size,:], ds_scaled[train_size:len(ds_scaled),:1]

len(ds_train),len(ds_test)

#creating dataset in time series for LSTM model 
#X[100,120,140,160,180] : Y[200]
def create_ds(dataset,step):
    Xtrain, Ytrain = [], []
    for i in range(len(dataset)-step-1):
        a = dataset[i:(i+step), 0]
        Xtrain.append(a)
        Ytrain.append(dataset[i + step, 0])
    return np.array(Xtrain), np.array(Ytrain)

#Taking 100 days price as one record for training
time_stamp = 100
X_train, y_train = create_ds(ds_train,time_stamp)
X_test, y_test = create_ds(ds_test,time_stamp)

X_train.shape,y_train.shape

X_test.shape, y_test.shape

#Reshaping data to fit into LSTM model
X_train = X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)
X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)

from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, LSTM

#Creating LSTM model using keras
model = Sequential()
model.add(LSTM(units=128,return_sequences=True,input_shape=(X_train.shape[1],1)))
model.add(LSTM(units=64,return_sequences=False))
#model.add(LSTM(units=50,return_sequences=True))
#model.add(LSTM(units=100, dropout=0.1))
model.add(Dense(units=25,activation='linear'))
model.add(Dense(units=1,activation='linear'))
model.summary()

#Training model with adam optimizer and mean squared error loss function
model.compile(loss='mean_squared_error',optimizer='adam', metrics=['accuracy'])
model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=64)

"""# Neuer Abschnitt"""

#PLotting loss, it shows that loss has decreased significantly and model trained well
loss = model.history.history['loss']
plt.plot(loss)

#Predicitng on train and test data
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

#Inverse transform to get actual value
train_predict = normalizer.inverse_transform(train_predict)
test_predict = normalizer.inverse_transform(test_predict)

#Comparing using visuals
plt.plot(normalizer.inverse_transform(ds_scaled))
plt.plot(train_predict)
plt.plot(test_predict)

type(train_predict)

test = np.vstack((train_predict,test_predict))

#Combining the predited data to create uniform data visualization
plt.plot(normalizer.inverse_transform(ds_scaled))
plt.plot(test)

len(ds_test)

#Getting the last 100 days records
fut_inp = ds_test[1408:]

fut_inp = fut_inp.reshape(1,-1)

tmp_inp = list(fut_inp)

fut_inp.shape

#Creating list of the last 100 data
tmp_inp = tmp_inp[0].tolist()

#Predicting next 1 days price suing the current data
#It will predict in sliding window manner (algorithm) with stride 1
lst_output=[]
n_steps=100
i=0
while(i<1):
    
    if(len(tmp_inp)>100):
        fut_inp = np.array(tmp_inp[1:])
        fut_inp=fut_inp.reshape(1,-1)
        fut_inp = fut_inp.reshape((1, n_steps, 1))
        yhat = model.predict(fut_inp, verbose=0)
        tmp_inp.extend(yhat[0].tolist())
        tmp_inp = tmp_inp[1:]
        lst_output.extend(yhat.tolist())
        i=i+1
    else:
        fut_inp = fut_inp.reshape((1, n_steps,1))
        yhat = model.predict(fut_inp, verbose=0)
        tmp_inp.extend(yhat[0].tolist())
        lst_output.extend(yhat.tolist())
        i=i+1
    

print(lst_output)

len(ds_scaled)

#Creating a dummy plane to plot graph one after another
plot_new=np.arange(1,101)
plot_pred=np.arange(101,102)
#plot_pred=np.arange(101,139)

plt.plot(plot_new, normalizer.inverse_transform(ds_scaled[4925:]))
plt.plot(plot_pred, normalizer.inverse_transform(lst_output))

ds_new = ds_scaled.tolist()

len(ds_new)

#Entends helps us to fill the missing value with approx value
ds_new.extend(lst_output)
plt.plot(ds_new[1200:])

#Creating final data for plotting
final_graph = normalizer.inverse_transform(ds_new).tolist()

#Plotting final results with predicted value after 1 Days
plt.plot(final_graph,)
plt.ylabel("Price")
plt.xlabel("Time")
plt.title("{0} prediction of next day close".format(stock_symbol))
plt.axhline(y=final_graph[len(final_graph)-1], color = 'red', linestyle = ':', label = 'NEXT 1D Close: {0}'.format(round(float(*final_graph[len(final_graph)-1]),2)))
plt.legend()







